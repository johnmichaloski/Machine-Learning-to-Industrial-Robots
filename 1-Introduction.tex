\newpage
\section{Introduction}
\sloppy
Approaches categorized as ``artificial intelligence'' (AI) are enabling significant advances in robotics. These include symbolic logic, Bayesian statistics, and numerous other algorithmic approaches. Recently, data-centric machine learning has become a prominent tool in a number of disciplines relevant to robotics.  AI applied to robotics ``can create smarter, faster, cheaper, and more environmentally-friendly production processes that can increase worker productivity, improve product quality, lower costs, and improve worker health and safety. Machine learning algorithms can improve the scheduling of manufacturing processes and reduce inventory requirements.''  AI's rapid rate of adoption has led to many successes, as well as the need for a measurement science infrastructure to help generate data and qualify it.  For industry to use AI, they must trust what comes out of the AI system. The key idea is to develop data sets and trained AI system, validated through performance evaluation techniques, to allow them to be applied to manufacturing robotic systems. This will allow manufacturers to gain more value from their robots by allowing the robot to ```learn'' new tasks, and how to better perform existing tasks, without the need for human intervention. NIST is uniquely qualified to address this because of our experience in robot performance characterization, information modeling standards, and robot programming.

\subsection{Criteria for Robotic AI/ML Applications}
Using AI/ML in physical systems is a daunting task. Errant behavior cannot be tolerated as efficacy as well as safety of expensive equipment are of important. Robots can be dangerous to themselves and others, especially those with deficient or poorly tested AI/ML algorithms. Thus, a key scientific and practical goal is to characterize the confidence of a given robotic AI/ML algorithm. This leads to performance  questions. For ML, is the volume of training data sufficient to learn and predict the expected behavior? How robust is the AI/ML to errors in the AI/ML model and the training data? 

Then issues related to developing an AI/ML application need to be addressed that is suitable to a robotics application. Is it possible to successfully train, test and evaluate the efficacy of an AI/ML algorithm or is the robotics learning problem fundamentally intractable?

 Such theoretical characterizations of machine-learning algorithms and problems typically make use of the familiar frameworks of statistical decision theory and computational complexity theory~\cite{Jordan255}. Attempts to characterize general machine-learning algorithms  have used statistical and computational theory in which the goal is to simultaneously characterize the sample complexity (how much data are required to learn accurately) and the computational complexity (how much computation is required) and to specify how these depend on features of the learning algorithm such as the representation it uses for what it learns~\cite{valiant1984theory,chandrasekaran2013computational}.
 
 It is typically out of the realm of robot application engineer  to ponder the data and computational complexity, but rather the intention is to leverage existing ML technologies and develop robot applications that are tractable and robust while providing predictable and safe behavior.  For a robot AI/ML application there need to be input, output, and timing guards and/or filters to prevent erratic or unsafe behavior. Kober et. al. point out it is often unrealistic to assume that the true state of a robot is completely observable and noise free, and therefore must often use a filter to estimate the true state~\cite{kober2013reinforcement}. Further for reinforcement learning training of an AI/ML system using a real physical system can be difficult and hard to reproduce.


\subsection{Embodied AI and Data Generation for Manufacturing Robotics}
 The Embodied AI and Data Generation for Manufacturing Robotics is a NIST project to explore data generating mechanisms (physical and virtual) across a variety of relevant experimental factors relevant to industrial robotic applications. Generated data will be organized and formatted in a way that will facilitate the training of AI applications in robotic software agility, perception, grasping, teaming, and mobility, and will include metadata that will define the dataâ€™s scope and applicability. The datasets and the associated approaches will be validated through its implementation on a robot, showing how the robot can directly solve a manufacturing task or improve existing performance. 

\begin{figure}[!h]
\centering
%\framebox{
\includegraphics*[]{./Figure/NIST_AI_Flowchart.jpg}
%}
\caption{Flow Chart of Robot Machine Learning Development and Dissemination at NIST}
\label{fg:aiml_flowchart} 
\end{figure}
The overreaching goal is the public sharing and collaboration of all elements of the NIST AI/ML robotics work. The sharing includes text, data sets, metadata, as well as algorithms. The generated data will be made available to researchers and industry practitioners to train and test AI systems for industrial robotic applications. The specifics regarding learning methods, settings, and code bases will be disseminated through publications, online data sets and open source code repositories. 


\subsection{Overview of Robot Machine Learning Process at NIST}
The public sharing of the NIST AI/ML robotics work will at the same time conform to both NIST and robotics research collaboration considerations.  Before any results can be disseminated at NIST, there is a  formal reviewing process that is required before one can disseminate any research.
Figure~\ref{fg:aiml_flowchart} shows the high level flow chart required to produce and disseminate the results of a Machine Learning robotics application at NIST. 

The first step in the process is to identify a robot application worthy of AI/ML. In this regard, a candidate AI/ML task would be one that solves or simplifies a given robot function. For example, assume we have an especially complicated robot that is difficult to program or difficult to maintain, should a potential AI/ML solution exist, then this would be a worthy solution candidate. 

Next, assuming an AI/ML robot application has been determined, a class of AI/ML neural net and the ML programming environment and toolkit needs to be selected and matched to the functional requirements. There are many capabilities as well as programming languages to be found in existing AI/ML tools. Some of the functionality available in various  AI/ML tools include: classification, regression, clustering, data preprocessing, dimensionality reduction, data flow, massive data sets, etc. In addition, the ability to use parallel programming technology (e.g., Graphics processing unit (GPU)) may be imperative for improving the neural net training speed  or the AI/ML application may be computationally intractable. To that note, NIST has a high performance computing platform called Enki which consists of a 13-node IBM Power9 system to assist in scientific computations driven by massive data sets, such as for AI/ML~\cite{enki}. 

Data set generation is an important element in building a successful AI/ML robot application. The data set sample complexity, size, and statistical distribution are among many of the concerns in training a neural network. There are abundant datasets to be found on the Internet~\cite{KaggleDatasets,UCIrvine,VisualData,DataGov}. However, a stated goal of the NIST AI/ML project is to generate useful robotic datasets.  There are two main types of datasets, either real or synthetic. A real dataset is generated from observing and recording actual real world events or experimental data. A synthetic dataset is generated programmatically or by a simulation.  This step may be an iterative process, as although the application may seem suitable, generating the appropriate data may prove unfeasible.


Once an application and a neural net programming framework has been selected, training and evaluation of the AI/ML application is performed. We assume a neural network is the machine learning algorithm used. Neural networks are one of the most common machine learning algorithms and are particularly good when applied to problems where there is a large amount of input data.  Through an input layer, one or more hidden layers, and an output layer, a neural network works by connecting up a series of neurons with weights assigned to each connection. As each connection is activated, a calculation is performed on the connection before passing through an activation function at each level of the hidden layers. Neural networks can be used without knowing precisely how the training operates, however, currently setting up the neural network requires an understanding of programming ML algorithms to consume training and evaluation data set. 


The next step is to verify the correctness of the AI/ML component inside a bigger robotic system.
At this point, performance testing turns from a virtual world into a physical world  with the robot to  evaluate the efficacy and correctness of the AI/ML neural network. The ability to comprehensively evaluate the quantitative and qualitative performance of an AI/ML system is critical to accurately predicting how it will perform in various situations. The performance evaluations is often as much of a challenge as is the design of the AI/ML applications themselves. Visualization is important for verifying the basic functionality correctness of the AI/ML. Clearly, if a simulated visualization has truly negative consequences, e.g., software crashes or timing issues such as jitter or produces errant behavior, then the AI/ML application is flawed. A systematic strategy to examine the AI/ML fidelity will be presented later. As in all software, there can exist bugs that are not readily apparent. Further, large output divergence resulting from close inputs can be particularly onerous as an expected ``routine'' answer can be catastrophic so safeguards must be in place.


In order to publish the AI/ML data, code and papers, a NIST approval process is required and it entails a multistep operation. Minimally, NIST Gaithersburg publications must go through a Washington Editorial Review Board (WERB) process to insure compliance to NIST publishing standards. Associated with the publication and in our case potentially more important, data now needs to go through a NIST MIDAS review process to ensure compliance with NIST data standards.  Every published NIST data and article now has a DOI established with each publication, either data or article. In addition, academic societies, such as IEEE,  have been working to establish reproducible robotics research through code publishing (using Code Ocean) as well as publication guidelines through Good Experimental Methodology (GEM). 





